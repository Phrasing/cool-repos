# cool repos

| Repository | Language | Description | Last Updated |
|---|---|---|---|
| **`Account Generators`** | | | |
| [`Spotify-Account-Creator`](https://github.com/seadhy/Spotify-Account-Creator) | Python | Spotify Account Creator + Follower Bot + Auto changing pfp (avatar) | 2024-06-25 |
| | | | |
| **`Anti-Bot Bypass`** | | | |
| [`Akamai`](https://github.com/i7solar/Akamai) | Go | Akamai 1.75 Cookie Generator for _abck and ak_bmsc | 2023-05-23 |
| [`akamai-sensor-data-tools`](https://github.com/klenne/akamai-sensor-data-tools) | JavaScript | This repository serves as a comprehensive resource for my studies of akamai solutions. | 2024-11-09 |
| [`akamai2.0-sensor_data`](https://github.com/xiaoweigege/akamai2.0-sensor_data) | JavaScript | sensor_data, akamai-bm-telemetry, _abck bypass | 2025-06-24 |
| [`chrome-recaptcha-harvester`](https://github.com/benastahl/chrome-recaptcha-harvester) | Python | Chrome Recaptcha Harvester supporting V2 and V3 | 2025-06-17 |
| [`Cloudflare-Cookie-Bypass`](https://github.com/seadhy/Cloudflare-Cookie-Bypass) | Python | Cloudflare __cf_bm cookie ( currently called cf_clearance ) bypass | 2025-05-06 |
| [`cloudflare-invisible-solver`](https://github.com/notemrovsky/cloudflare-invisible-solver.git) | Python | cloudflare invisible challenge solver | 2025-05-12 |
| [`cloudflare-jsd`](https://github.com/xKiian/cloudflare-jsd) | JavaScript | Bypass Cloudflare's /h/b/jsd challenge using 100% python | 2025-06-27 |
| [`CloudflareBypassForScraping`](https://github.com/sarperavci/CloudflareBypassForScraping) | Python | A cloudflare verification bypass script for webscraping | 2025-05-22 |
| [`GoogleRecaptchaBypass`](https://github.com/sarperavci/GoogleRecaptchaBypass) | Python | Solve Google reCAPTCHA in less than 5 seconds! üöÄ | 2025-06-12 |
| [`perimeterx-utils-go`](https://github.com/incizzle/perimeterx-utils-go) | Go | Helper functions for perimeterx | 2021-03-13 |
| [`PerimiterXCudaSolver`](https://github.com/re-jevi/PerimiterXCudaSolver) | Cuda | Solver for perimiterX PoW in cuda to allow faster solving | 2025-05-17 |
| [`px-grubhub-mobile`](https://github.com/obfio/px-grubhub-mobile) | Go | PX SDK API in golang made for my blog at https://antibot.blog | 2023-09-02 |
| [`px-mobile-api`](https://github.com/AzureFlow/px-mobile-api) | TypeScript | Multi-version PX Mobile solver. | 2024-03-16 |
| [`reese84-rs`](https://github.com/manudeobs/reese84-rs) | Rust |  | 2025-04-24 |
| [`trickster.dev-code`](https://github.com/rl1987/trickster.dev-code) | Python |  | 2025-06-14 |
| [`turnstile-rs`](https://github.com/manudeobs/turnstile-rs.git) | Rust |  | 2025-04-25 |
| [`utmvc-rs`](https://github.com/manudeobs/utmvc-rs) | Rust |  | 2025-04-24 |
| | | | |
| **`Misc`** | | | |
| [`ants`](https://github.com/panjf2000/ants) | Go | üêúüêúüêú ants is the most powerful and reliable pooling solution for Go. | 2025-04-12 |
| [`go-graphql-client`](https://github.com/hasura/go-graphql-client) | Go | Package graphql provides a GraphQL client implementation. | 2025-06-20 |
| [`proxy-checker`](https://github.com/seadhy/proxy-checker) | Python | Audits your proxies and saves them by categorizing them. | 2023-08-10 |
| [`yellowstone-grpc-client`](https://github.com/manudeobs/yellowstone-grpc-client) | Rust |  | 2025-05-23 |
| | | | |
| **`Other Curated Lists`** | | | |
| [`awesome-reversing`](https://github.com/tylerha97/awesome-reversing) |  | A curated list of awesome reversing resources | 2023-08-19 |
| [`awesome-web-security`](https://github.com/qazbnm456/awesome-web-security) |  | üê∂ A curated list of Web Security materials and resources. | 2025-05-02 |
| | | | |
| **`Reverse Engineering`** | | | |
| [`Akamai-2.0-Deobfuscator`](https://github.com/manudeobs/Akamai-2.0-Deobfuscator) | JavaScript |  | 2023-12-03 |
| [`hooker`](https://github.com/CreditTone/hooker) | JavaScript | üî•üî• hooker is a Frida-based reverse engineering toolkit for Android. It offers a user-friendly CLI, universal scripts, auto hook generation, memory roaming to detect activities/services, one-click SOCKS5 proxy setup, Frida JustTrustMe, and BoringSSL unpinning for all apps. | 2025-06-25 |
| [`Imperva-Reverse`](https://github.com/botswin/Imperva-Reverse) | JavaScript |  | 2025-07-04 |
| [`obfuscator-io-deobfuscator`](https://github.com/ben-sb/obfuscator-io-deobfuscator.git) | TypeScript | A deobfuscator for scripts obfuscated by Obfuscator.io | 2025-06-20 |
| | | | |
| **`TLS Fingerprinting`** | | | |
| [`adyen-risk`](https://github.com/AzureFlow/adyen-risk) | JavaScript | Generates Ayden's device fingerprint (dfValue). | 2024-03-24 |
| [`adyen_df_python`](https://github.com/benastahl/adyen_df_python) | Python | Generates Adyen device fingerprint | 2024-04-30 |
| [`Chromium_FingerPrint_Tutorial`](https://github.com/xiaoweigege/Chromium_FingerPrint_Tutorial) |  | ChromiumÊåáÁ∫πÊµèËßàÂô®ÂºÄÂèëÊïôÁ®ãÔºåÂ∏ÆÂä©‰Ω†‰∫ÜËß£ChromiumÂÜÖÊ†∏ÔºåÂπ∂‰∏îÂºÄÂèëÂá∫‰∏ÄÂ•óÂü∫Á°ÄÁöÑÊåáÁ∫πÊµèËßàÂô®„ÄÇ | 2025-06-04 |
| [`tls-client`](https://github.com/bogdanfinn/tls-client) | Go | net/http.Client like HTTP Client with options to select specific client TLS Fingerprints to use for requests.  | 2025-06-17 |
| | | | |
| **`Web Automation`** | | | |
| [`discord-server-cloner`](https://github.com/xKiian/discord-server-cloner) | Python | scrape a whole discord server in seconds (with every channel, every role and every emoji) | 2023-06-04 |
| [`github-profile-views-booster`](https://github.com/seadhy/github-profile-views-booster) | Python | Github profile counter booster built using python and the httpx module. | 2023-08-10 |
| [`Haven-AIO`](https://github.com/Slikcodez/Haven-AIO) | Go | Haven AIO is a request based Hibbett bot in Golang. It has allowed users to secure hundreds of sneakers swiftly during drops and restocks. It was developed by primarily @Slikcodez, but also @cyrusnaficy and @StefanAraujo contributed | 2023-05-08 |
| [`human_mouse`](https://github.com/sarperavci/human_mouse) | Python | üéØ Ultra-realistic human mouse movements using bezier curves and spline interpolation. Natural cursor automation. | 2025-05-01 |
| [`kick-unofficial-api`](https://github.com/sarperavci/kick-unofficial-api.git) | Python | üõ°Ô∏è Unofficial Kick.com API wrapper with automatic bypass protection. | 2025-01-27 |
| [`OxyMouse`](https://github.com/xiaoweigege/OxyMouse) | Python | Mouse Movement Algorithms | 2024-09-25 |
| [`ResyBot`](https://github.com/TCWTEAM/ResyBot) | Python | Resy Bot with captcha bypass, proxy support, no rate-limiting | 2024-12-29 |
| | | | |
| **`Web Frameworks`** | | | |
| [`scrapy`](https://github.com/scrapy/scrapy) | Python | Scrapy, a fast high-level web crawling & scraping framework for Python. | 2025-07-02 |


<details>
<summary>View the script used to generate this page</summary>

```python
import os
import re
import subprocess
import json
from datetime import datetime
import google.generativeai as genai
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm


def get_categories_in_batch(repos_to_categorize, existing_categories):
    """Sends a batch of repositories to Gemini and gets categories."""
    print(
        f"  > Asking Gemini to categorize {len(repos_to_categorize)} repositories in a single batch..."
    )
    repos_json_string = json.dumps(repos_to_categorize, indent=2)

    prompt = f"""You are an expert programmer and a helpful API that categorizes GitHub repositories.
You will be given a JSON array of repositories. Your task is to return a single, valid JSON array of the same repositories, each with an added "category" field.

- If a fitting category already exists, please use it.
- Your entire response must be only the JSON array and nothing else.
- Do not be overly specific; try to keep the number of categories low.

Example Categories: Anti-Bot Bypass, Web Automation, Reverse Engineering, Misc, Web Frameworks, Account Generators, TLS Fingerprinting, Other Curated Lists.
Existing Categories: {', '.join(existing_categories) if existing_categories else 'None'}

Here is the JSON array of repositories to categorize:
{repos_json_string}
"""
    try:
        model = genai.GenerativeModel("gemini-2.5-pro")  # type: ignore
        response = model.generate_content(prompt)
        cleaned_json_text = response.text.strip().lstrip("```json").rstrip("```")
        categorized_list = json.loads(cleaned_json_text)
        return {item["name"]: item["category"] for item in categorized_list}
    except Exception as e:
        print(f"  ! Error with Gemini API batch processing: {e}")
        return {}


def parse_readme(path):
    repos_by_category = {}
    if not os.path.exists(path):
        return repos_by_category

    row_regex = re.compile(
        r"\|\s*\[`(.+?)`\]\((.+?)\)\s*\|"  # 1: name, 2: url
        r"\s*(.*?)\s*\|"  # 3: language
        r"\s*(.*?)\s*\|"  # 4: description
        r"\s*(.*?)\s*\|"  # 5: date
    )

    current_category = "Uncategorized"
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            category_match = re.search(r"\|\s*\*\*`(.+?)`\*\*\s*\|", line)
            if category_match:
                current_category = category_match.group(1).strip()
                continue

            row_match = row_regex.search(line)
            if row_match:
                name, url, lang, desc, date = [m.strip() for m in row_match.groups()]

                clean_row = f"| [`{name}`]({url}) | {lang} | {desc} | {date} |"

                if current_category not in repos_by_category:
                    repos_by_category[current_category] = []
                repos_by_category[current_category].append(clean_row)

    return repos_by_category


def get_git_data(p):
    try:
        url = subprocess.run(
            ["git", "config", "--get", "remote.origin.url"],
            cwd=p,
            capture_output=True,
            check=True,
            encoding="utf-8",
        ).stdout.strip()
        gh_process = subprocess.run(
            [
                "gh",
                "repo",
                "view",
                url,
                "--json",
                "description,pushedAt,primaryLanguage",
            ],
            capture_output=True,
            check=True,
            encoding="utf-8",
            errors="replace",
        )
        repo_data = json.loads(gh_process.stdout)
        desc = repo_data.get("description") or ""
        pushed_at_str = repo_data.get("pushedAt", "")
        lang_data = repo_data.get("primaryLanguage")
        lang = lang_data.get("name") if lang_data else ""
        date_formatted = ""
        if pushed_at_str:
            date_obj = datetime.fromisoformat(pushed_at_str.replace("Z", "+00:00"))
            date_formatted = date_obj.strftime("%Y-%m-%d")
        return url, desc, date_formatted, lang
    except (subprocess.CalledProcessError, FileNotFoundError, json.JSONDecodeError):
        return None, None, None, None


def main():
    readme_path = "README.md"
    repos_by_category = parse_readme(readme_path)
    existing_names = {
        repo_name
        for rows in repos_by_category.values()
        for row in rows
        for repo_name in re.findall(r"\[`(.+?)`\]", row)
    }
    cwd = os.getcwd()
    new_repos_data = []

    all_local_dirs = sorted(
        [
            d
            for d in os.listdir(cwd)
            if os.path.isdir(os.path.join(cwd, d))
            and os.path.exists(os.path.join(cwd, d, ".git"))
        ]
    )
    new_dirs_to_process = [d for d in all_local_dirs if d not in existing_names]
    new_repo_paths = [os.path.join(cwd, d) for d in new_dirs_to_process]

    if not new_repo_paths:
        print("\nREADME.md is already up to date.")
        return

    print(f"\nFetching data for {len(new_repo_paths)} new repositories...")
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(
            tqdm(executor.map(get_git_data, new_repo_paths), total=len(new_repo_paths))
        )

    for i, (url, desc, last_updated, lang) in enumerate(results):
        if url:
            new_repos_data.append(
                {
                    "name": new_dirs_to_process[i],
                    "url": url,
                    "desc": desc,
                    "last_updated": last_updated,
                    "lang": lang,
                }
            )

    repo_info_for_gemini = [
        {"name": r["name"], "description": r["desc"], "language": r["lang"]}
        for r in new_repos_data
    ]
    categorized_repos = get_categories_in_batch(
        repo_info_for_gemini, list(repos_by_category.keys())
    )

    if not categorized_repos:
        print("\nCould not get categories from Gemini. Aborting update.")
        return

    for repo_data in new_repos_data:
        repo_name = repo_data["name"]
        category_input = categorized_repos.get(repo_name, "Uncategorized")
        lang_text = repo_data["lang"] or ""

        new_row = f"| [`{repo_name}`]({repo_data['url']}) | {lang_text} | {repo_data['desc'] or ''} | {repo_data['last_updated'] or ''} |"

        if category_input not in repos_by_category:
            repos_by_category[category_input] = []
        repos_by_category[category_input].append(new_row)
        print(f"  + Processed '{repo_name}' into category '{category_input}'")

    md_content = "# cool repos\n\n"
    md_content += (
        "| Repository | Language | Description | Last Updated |\n|---|---|---|---|\n"
    )
    all_rows = []
    is_first_category = True
    for category, rows in sorted(repos_by_category.items()):
        if not is_first_category:
            all_rows.append("| | | | |")
        all_rows.append(f"| **`{category}`** | | | |")
        all_rows.extend(sorted(rows, key=lambda line: line.split("`")[1].lower()))
        is_first_category = False

    md_content += "\n".join(all_rows)

    with open(__file__, "r", encoding="utf-8") as f:
        source_code = f.read()

    source_block = f"""
<details>
<summary>View the script used to generate this page</summary>

```python
{source_code}
"""
    md_content += "\n\n" + source_block
    with open(readme_path, "w", encoding="utf-8") as f:
        f.write(md_content)

    print(
        f"\n‚úÖ Successfully updated README.md with {len(new_repos_data)} new repositories!"
    )


if __name__ == "__main__":
    main()

